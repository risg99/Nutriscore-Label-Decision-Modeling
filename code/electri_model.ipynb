{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/final_preprocessed_data_points.csv')\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = \"energy-kj_100g\"\n",
    "su = \"sugars_100g\"\n",
    "fa = \"saturated-fat_100g\"\n",
    "sa = \"sodium_100g\"\n",
    "pr = \"proteins_100g\"\n",
    "fi = \"fiber_100g\"\n",
    "fr = \"fruits-vegetables-nuts-estimate-from-ingredients_100g\"\n",
    "\n",
    "profiles = df.loc[:,[en, su, fa, sa, pr, fi, fr]]\n",
    "print(profiles.shape)\n",
    "profiles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop data with saturated fat_100g > 10\n",
    "profiles = profiles[profiles[fa] <= 5.1]\n",
    "profiles = profiles[profiles[su] <= 35]\n",
    "profiles = profiles[profiles[pr] <= 30]\n",
    "profiles = profiles[profiles[fr] <= 60]\n",
    "profiles = profiles[profiles[sa] <= 0.81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting quantiles using numpy.percentile() for distinct columns values\n",
    "quantiles = {}\n",
    "for col in profiles.columns:\n",
    "    quantiles[col] = np.percentile(profiles[col].unique(), [0, 20, 40, 60, 80, 100])\n",
    "\n",
    "# Plotting distribution curves for each column\n",
    "for col in profiles.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(profiles[col], kde=True, bins=30, color='green', stat='density')\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Density')\n",
    "    for q in quantiles[col]:\n",
    "        plt.axvline(x=q, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_dict = {}\n",
    "\n",
    "# Creating a dictionary of criteria for each column\n",
    "for col in profiles.columns:\n",
    "    each_criteria = []\n",
    "    for i in range(5):\n",
    "        each_criteria.append((quantiles[col][i], quantiles[col][i+1]))\n",
    "    profile_dict[col] = each_criteria\n",
    "\n",
    "print(profile_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    # {en: 1, su: 1, fa: 1, sa: 1, pr: 2, fi: 2, fr: 2}, #weights 1\n",
    "    # {en: 2, su: 2, fa: 2, sa: 2, pr: 1, fi: 1, fr: 1}, #weights 2\n",
    "    # {en: 0, su: 1, fa: 1, sa: 1, pr: 1, fi: 1, fr: 1}, #weights 3\n",
    "    {en: 0, su: 2, fa: 4, sa: 0.8, pr: 2, fi: 1, fr: 0.5}, #our model\n",
    "    # {en: 1, su: 1, fa: 1, sa: 1, pr: 5, fi: 5, fr: 5}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimisticMajoritySorting(data, profile_dict, weights):\n",
    "    # build MR-Sort based on the profile_dict and weights, return the data with the categories assiged to it\n",
    "    # loop over the data columns, check the value of each row use the weights it if it exceed the threshold y = 0.6, assign the category to the row\n",
    "    # if the row does not exceed the threshold, assign it to the next category\n",
    "    # reverse the  profile_dict\n",
    "    for col in data.columns:\n",
    "        for i in range(len(profile_dict[col])):\n",
    "            # print(profile_dict[col][i])\n",
    "            # print(profile_dict[col][i][0])\n",
    "            # print(profile_dict[col][i][1])\n",
    "            # print(data[col])\n",
    "            # print((data[col] >= profile_dict[col][i][0]))\n",
    "            # print((data[col] <= profile_dict[col][i][1]))\n",
    "            # if the value of the row is between the range of the category, assign the category to the row by taking the threshold into account\n",
    "            data.loc[(data[col] >= profile_dict[col][i][0]) & (data[col] <= profile_dict[col][i][1]), col] = i\n",
    "            # return data\n",
    "    data.to_csv('../data/preprocessed_elctri_model_col.csv', index=False) \n",
    "    # calculate the score for each row\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_dict = {}\n",
    "\n",
    "for key, value in profile_dict.items():\n",
    "    reversed_tuples = [(tup[1], tup[0]) for tup in value[::-1]]  # Reversing the tuples elements\n",
    "    reversed_dict[key] = reversed_tuples\n",
    "\n",
    "print(reversed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIP THIS next code, but don't delete it!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PessimisticMajoritySorting(data_0, profile_dict, weights, thresholdPercentage):\n",
    "#     \"\"\"\n",
    "#     This function performs Pessimistic Majority Sorting based on the profile_dict and weights.\n",
    "#     It assigns categories to the data based on the majority sorting algorithm.\n",
    "\n",
    "#     Parameters:\n",
    "#     - data: pandas DataFrame, the input data\n",
    "#     - profile_dict: dictionary, the profile dictionary containing the thresholds for each column\n",
    "#     - weights: list of dictionaries, the weights for each category\n",
    "\n",
    "#     Returns:\n",
    "#     - data: pandas DataFrame, the data with assigned categories\n",
    "#     \"\"\"\n",
    "#     # Make a copy of the data\n",
    "#     data = pd.DataFrame.copy(data_0)\n",
    "#     # define the columns \n",
    "#     columns = [en, su, fa, sa, pr, fi, fr]\n",
    "#     error_rate = 0.001  # The error rate for the algorithm\n",
    "#     # Iterate over each row and update cells based on conditions\n",
    "#     for index, row in data.iterrows():\n",
    "#         for col in columns:\n",
    "#             for i in range(len(profile_dict[col])):\n",
    "#                 lower_bound = profile_dict[col][i][1]\n",
    "#                 upper_bound = profile_dict[col][i][0]\n",
    "#                 if (lower_bound + error_rate) < row[col] <= (upper_bound + error_rate):\n",
    "#                     data.at[index, col] = i +1 # shift the category by 1\n",
    "#                     break  # Stop checking other ranges once a match is found\n",
    "#     # for each column in the data, multiply the value of the row by the weight of the category\n",
    "#     for col in columns:\n",
    "#         for i in range(len(profile_dict[col])):\n",
    "#             data.loc[data[col] == i, col] = weights[0][col] * i\n",
    "#     # calculate the score for each row\n",
    "#     data['score'] = data[columns].sum(axis=1)\n",
    "\n",
    "#     # calculate the threshold for the score based on the threshold percentage\n",
    "#     theshold = thresholdPercentage /100 * (len(next(iter(profile_dict.items()))[1]) * len(columns)) # the threshold for the score 50%\n",
    "\n",
    "#     print(theshold)\n",
    "#     # # assign the category between A, B, C, D, E based on the score and the threshold\n",
    "#     for index, row in data.iterrows():\n",
    "#         if row['score'] >= theshold:\n",
    "#             data.at[index, 'category'] = 'A'\n",
    "#         elif row['score'] >= theshold * 0.8:\n",
    "#             data.at[index, 'category'] = 'B'\n",
    "#         elif row['score'] >= theshold * 0.6:\n",
    "#             data.at[index, 'category'] = 'C'\n",
    "#         elif row['score'] >= theshold * 0.4:\n",
    "#             data.at[index, 'category'] = 'D'\n",
    "#         else:\n",
    "#             data.at[index, 'category'] = 'E'\n",
    "\n",
    "#     # # Save the data to a CSV file\n",
    "#     # data.to_csv('../data/preprocessed_elctri_model_col.csv', index=False) \n",
    "\n",
    "#     # Return the data with assigned categories\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PessimisticMajoritySorting(data_0, profile_dict, weights, thresholdPercentage, columns):\n",
    "    \"\"\"\n",
    "    This function performs Pessimistic Majority Sorting based on the profile_dict and weights.\n",
    "    It assigns categories to the data based on the majority sorting algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - data_0: pandas DataFrame, the input data\n",
    "    - profile_dict: dictionary, the profile dictionary containing the thresholds for each column\n",
    "    - weights: list of dictionaries, the weights for each category\n",
    "    - thresholdPercentage: float, the threshold percentage for the score\n",
    "    - columns: list, the columns to consider for sorting\n",
    "\n",
    "    Returns:\n",
    "    - data: pandas DataFrame, the data with assigned categories\n",
    "    \"\"\"\n",
    "    # Make a copy of the data\n",
    "    data = data_0.copy()\n",
    "    sum_of_weights = sum(weights[0].values())\n",
    "    \n",
    "    # calculate the threshold for the score based on the threshold percentage\n",
    "    threshold = thresholdPercentage * (len(next(iter(profile_dict.items()))[1]) * sum_of_weights) / 100\n",
    "    \n",
    "    error_rate = 0.01  # The error rate for the algorithm\n",
    "    \n",
    "    # Iterate over each row and update cells based on conditions\n",
    "    for index, row in data.iterrows():\n",
    "        category_flag = False\n",
    "        # i represents the category index\n",
    "        for i in range(len(next(iter(profile_dict.items()))[1])):\n",
    "            sum_v = 0  # sum of the weighted sum of the categories\n",
    "            for col in columns:\n",
    "                lower_bound = profile_dict[col][i][1]\n",
    "                upper_bound = profile_dict[col][i][0]\n",
    "                if row[col] > (lower_bound - error_rate):\n",
    "                    sum_v += weights[0][col] * sum_of_weights * (i + 1)\n",
    "                    continue  # Stop checking for this column once a match is found\n",
    "                else:\n",
    "                    break\n",
    "            if sum_v >= threshold:\n",
    "                data.at[index, 'category'] = chr(69 - i)  # shift the category by 1\n",
    "                category_flag = True\n",
    "                break  # skip the rest of the categories\n",
    "            else:\n",
    "                continue\n",
    "        if not category_flag:\n",
    "            data.at[index, 'category'] = 'A'  # assign category 'E' if no category is assigned\n",
    "    \n",
    "    # Return the data with assigned categories\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiles = df.loc[:,[en, su, fa, sa, pr, fi, fr]]\n",
    "# # drop duplicates from the data\n",
    "# profiles = profiles.drop_duplicates()\n",
    "# columns = [en, su, fa, sa, pr, fi, fr]\n",
    "# # use the fucntion PessimisticMajoritySorting\n",
    "# thresholdPercentage = 70\n",
    "# data_70 = pd.DataFrame(PessimisticMajoritySorting(df, reversed_dict, weights, thresholdPercentage, columns))\n",
    "# data_70.to_csv('../data/preprocessed_elctri_model_col.csv', index=False)\n",
    "# data_60 = pd.DataFrame(PessimisticMajoritySorting(df, reversed_dict, weights, thresholdPercentage -10, columns))\n",
    "# data_50 = pd.DataFrame(PessimisticMajoritySorting(df, reversed_dict, weights, thresholdPercentage - 20, columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiles = df.loc[:,[en, su, fa, sa, pr, fi, fr, 'nutrition_grade_fr']]\n",
    "# drop duplicates from the data\n",
    "profiles = profiles.drop_duplicates()\n",
    "columns = [en, su, fa, sa, pr, fi, fr]\n",
    "# use the fucntion PessimisticMajoritySorting\n",
    "thresholdPercentage = 70\n",
    "data_70 = pd.DataFrame(PessimisticMajoritySorting(profiles, reversed_dict, weights, thresholdPercentage, columns))\n",
    "# data_70.to_csv('../data/preprocessed_elctri_model_col.csv', index=False)\n",
    "# data_60 = pd.DataFrame(PessimisticMajoritySorting(profiles, reversed_dict, weights, thresholdPercentage -10, columns))\n",
    "# data_50 = pd.DataFrame(PessimisticMajoritySorting(profiles, reversed_dict, weights, thresholdPercentage - 20, columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_70.shape, data_70.head(2))\n",
    "# print(data_60.shape, data_60.head(2))\n",
    "# print(data_50.shape, data_50.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names to plot from each DataFrame\n",
    "col_df1 = 'category'  # Change this to your desired column from df1\n",
    "\n",
    "# Create separate plots for each DataFrame\n",
    "fig, axs = plt.subplots(1,4, figsize=(12, 4))\n",
    "\n",
    "# Plotting DataFrame 1\n",
    "value_counts_70 = data_70[col_df1].value_counts()\n",
    "axs[0].bar(value_counts_70.index, value_counts_70.values, width=0.4, align='center', label='DF70')\n",
    "axs[0].set_title('DataFrame 70%')\n",
    "\n",
    "# Plotting DataFrame 2\n",
    "value_counts_60 = data_60[col_df1].value_counts()\n",
    "axs[1].bar(value_counts_60.index, value_counts_60.values, width=0.4, align='center', label='DF60')\n",
    "axs[1].set_title('DataFrame 60%')\n",
    "\n",
    "# Plotting DataFrame 3\n",
    "value_counts_50 = data_50[col_df1].value_counts()\n",
    "axs[2].bar(value_counts_50.index, value_counts_50.values, width=0.4, align='center', label='DF50')\n",
    "axs[2].set_title('DataFrame 50%')\n",
    "\n",
    "# Plotting DataFrame 4\n",
    "value_counts_origianl = data_50['nutrition_grade_fr'].value_counts()\n",
    "axs[3].bar(value_counts_origianl.index, value_counts_origianl.values, width=0.4, align='center', label='Original')\n",
    "axs[3].set_title('Original')\n",
    "\n",
    "# Adding labels, legend, and adjusting layout\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Category')\n",
    "    ax.set_ylabel('Value Counts')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix using crosstab\n",
    "confusion_matrix = pd.crosstab(data_50['nutrition_grade_fr'], data_50['category'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n",
    "# Plotting the confusion matrix as a heatmap using Seaborn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix using crosstab\n",
    "confusion_matrix = pd.crosstab(data_60['nutrition_grade_fr'], data_60['category'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n",
    "# Plotting the confusion matrix as a heatmap using Seaborn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix using crosstab\n",
    "confusion_matrix = pd.crosstab(data_70['nutrition_grade_fr'], data_70['category'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n",
    "# Plotting the confusion matrix as a heatmap using Seaborn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
