{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e2149c-4c40-47fe-ae05-6256bab97fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ../requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b38bc8-ae1e-4d61-a9ef-5f70c1c8586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeafc276-b8dd-4057-b30b-27f396cba080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_products_by_category(category):\n",
    "    url = f\"https://world.openfoodfacts.org/cgi/search.pl?action=process&tagtype_0=categories&tag_contains_0=contains&tag_0={category}&page_size=100&json=true\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        products_data = response.json()[\"products\"]\n",
    "        products_df = pd.DataFrame(products_data)\n",
    "        return products_df\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {category}\")\n",
    "        return None\n",
    "\n",
    "categories = [\"Biscuits\", \"Breads\", \"Nuts\", \"Sandwiches\", \"Snacks\", \"Meat alternatives\", \"Chocolate candies\", \"Breakfast cereals\", \"Fruits\"]\n",
    "\n",
    "combined_products = pd.DataFrame()\n",
    "\n",
    "# Extract and combine products for each category\n",
    "for category in categories:\n",
    "    products_df = extract_products_by_category(category)\n",
    "    if products_df is not None:\n",
    "        combined_products = pd.concat([combined_products, products_df], ignore_index=True)\n",
    "\n",
    "# Remove duplicates\n",
    "combined_products.drop_duplicates(subset=\"product_name\", keep=\"first\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa21b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_file_name = \"combined_products.csv\"\n",
    "combined_products.to_csv('../data/'+combined_file_name, index=False)\n",
    "print(f\"Combined products saved to {combined_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08de79",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389db4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/combined_products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[\"_id\", \"image_url\", \"brands\", \"pnns_groups_2\", \"nutriments\", \"nutriscore_data\", \"nutrition_grade_fr\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1391edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that has no values\n",
    "df2.dropna(subset=['nutriments'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf192ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db51ca2",
   "metadata": {},
   "source": [
    "# Flatten the column nutriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6dc799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd50e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'nutriments' is the column with JSON data in DataFrame df2\n",
    "# Replace single quotes with double quotes in the 'nutriments' column\n",
    "df2['nutriments'] = df2['nutriments'].str.replace(\"'\", '\"')\n",
    "\n",
    "# Load JSON strings within 'nutriments' column\n",
    "df2['nutriments'] = df2['nutriments'].apply(json.loads)\n",
    "\n",
    "# Flatten the JSON column into separate columns\n",
    "df_nutriments = pd.json_normalize(df2['nutriments'])\n",
    "\n",
    "# Concatenate the flattened columns with the original DataFrame\n",
    "df2 = pd.concat([df2, df_nutriments], axis=1)\n",
    "\n",
    "# Drop the original 'nutriments' column if needed\n",
    "df2.drop(columns=['nutriments'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522fca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(subset=['nutriscore_data'], inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive the nutriscore data for one sample\n",
    "df2['nutriscore_data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate and convert JSON strings to dictionaries\n",
    "def validate_json(json_str):\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        # Attempt to replace single quotes with double quotes and retry decoding\n",
    "        try:\n",
    "            json_str = json_str.replace(\"'\", '\"')\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            return None  # Return None for invalid JSON strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'nutriments' is the column with JSON data in DataFrame df2\n",
    "# Replace single quotes with double quotes in the 'nutriments' column\n",
    "# df2['nutriscore_data'] = df2['nutriscore_data'].str.replace(\"'\", '\"')\n",
    "\n",
    "df2['nutriscore_data'] = df2['nutriscore_data'].apply(validate_json)\n",
    "\n",
    "# Load JSON strings within 'nutriments' column\n",
    "# df2['nutriscore_data'] = df2['nutriscore_data'].apply(json.loads)\n",
    "\n",
    "# Flatten the JSON column into separate columns\n",
    "df_nutriscore_data = pd.json_normalize(df2['nutriscore_data'])\n",
    "\n",
    "# Concatenate the flattened columns with the original DataFrame\n",
    "df3 = pd.concat([df2, df_nutriscore_data], axis=1)\n",
    "\n",
    "# Drop the original 'nutriments' column if needed\n",
    "df3.drop(columns=['nutriscore_data'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['negative_points'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('../data/combined_products_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter negative_points and keep <= 11\n",
    "df3 = df3[df3['negative_points'] <= 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['positive_points'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695891dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to keep in the final df\n",
    "to_keep_columns = [\"_id\", \"image_url\", \"brands\", \"pnns_groups_2\", \"energy-kj_100g\", \"sugars_100g\",\n",
    "                  \"salt_100g\", \"saturated-fat_100g\", \"proteins_100g\", \"fiber_100g\", \n",
    "                   \"fruits-vegetables-nuts-estimate-from-ingredients_100g\",\n",
    "                  \"sodium_100g\", \"nutrition-score-fr_100g\", \"nutrition_grade_fr\", \"negative_points\", \"positive_points\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513cd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df3[to_keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows\n",
    "len(df_final.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bdf786",
   "metadata": {},
   "source": [
    "# randomly sample 150 items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4846855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where any column contains NaN values\n",
    "df_no_na = df_final.dropna()\n",
    "\n",
    "# Calculate the number of samples to take for each unique value in 'pnns_groups_2' column\n",
    "num_samples = 300 // df_no_na['pnns_groups_2'].nunique()\n",
    "\n",
    "# Create an empty DataFrame to store sampled data\n",
    "sampled_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through each unique value in 'pnns_groups_2', sample the data, and append to the sampled_data DataFrame\n",
    "for group_value in df_no_na['pnns_groups_2'].unique():\n",
    "    group_data = df_no_na[df_no_na['pnns_groups_2'] == group_value].sample(min(num_samples, len(df_no_na[df_no_na['pnns_groups_2'] == group_value])))\n",
    "    sampled_data = pd.concat([sampled_data, group_data])\n",
    "\n",
    "# If the total number of samples is less than 150, sample the remaining randomly\n",
    "remaining_samples = 300 - len(sampled_data)\n",
    "if remaining_samples > 0:\n",
    "    remaining_data = df_no_na.sample(min(remaining_samples, len(df_no_na)))\n",
    "    sampled_data = pd.concat([sampled_data, remaining_data])\n",
    "\n",
    "# Final sampled DataFrame with approximately 150 items\n",
    "final_sample = sampled_data.sample(n=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722810f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data.to_csv(\"../data/final_preprocessed_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
