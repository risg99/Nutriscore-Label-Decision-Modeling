{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/final_preprocessed_data_points.csv')\n",
    "print(data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnotherMethodNutriScore(data):\n",
    "\n",
    "    # Initialize classifiers\n",
    "    classifiers = {\n",
    "        'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=7, random_state=0),\n",
    "        'Random Forest': RandomForestClassifier(max_depth=5, random_state=0),\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Gaussian Naive Bayes': GaussianNB(),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=15)\n",
    "    }\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "    y_train = le.transform(data[['nutrition_grade_fr']])\n",
    "\n",
    "    # Select columns of interests\n",
    "    columns_of_interest = ['energy-kj_100g', 'sugars_100g', 'salt_100g', 'saturated-fat_100g',\n",
    "                        'proteins_100g', 'fiber_100g', 'fruits-vegetables-nuts-estimate-from-ingredients_100g', 'sodium_100g']\n",
    "\n",
    "    X_train = data.iloc[:,4:11]\n",
    "\n",
    "    # Fit classifiers and store predicted values for each sample\n",
    "    # for clf_name, clf in classifiers.items():\n",
    "    #     clf.fit(X_train, y_train)\n",
    "    #     y_pred = clf.predict(X_train)\n",
    "    #     data[f'{clf_name}_predicted'] = le.inverse_transform(y_pred)  \n",
    "\n",
    "    # Assuming X_train, y_train, le, and classifiers are defined as before\n",
    "    # Splitting data for visualization purposes\n",
    "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize an empty dictionary to store accuracy results\n",
    "    accuracy_results = {}\n",
    "\n",
    "    # Function to plot confusion matrix\n",
    "    def plot_and_save_confusion_matrix(true_values, predicted_values, classifier_name, ax):\n",
    "        true_values_encoded = le.transform(true_values)\n",
    "        predicted_values_encoded = le.transform(predicted_values)\n",
    "        \n",
    "        cm = confusion_matrix(true_values_encoded, predicted_values_encoded)\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', ax=ax)\n",
    "\n",
    "        # Set x and y tick labels using LabelEncoder's inverse_transform\n",
    "        ax.set_xticklabels(le.inverse_transform(range(len(cm))))\n",
    "        ax.set_yticklabels(le.inverse_transform(range(len(cm))))\n",
    "\n",
    "        ax.set_title(f'Confusion Matrix for {classifier_name}')\n",
    "        ax.set_xlabel('Predicted Score')\n",
    "        ax.set_ylabel('Actual Score')\n",
    "\n",
    "    # Calculate number of rows and columns needed for subplots\n",
    "    num_classifiers = len(classifiers)\n",
    "    num_rows = 2  # 2 rows\n",
    "    num_cols = (num_classifiers + 1) // num_rows  # Adjusted columns to fit all classifiers\n",
    "\n",
    "    # Create subplots dynamically\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "\n",
    "    # Flatten axes if it's not a 2D array\n",
    "    if num_classifiers == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Iterate through classifiers and plot confusion matrices\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        clf.fit(X_train_split, y_train_split)\n",
    "        y_pred = clf.predict(X_test_split)\n",
    "        accuracy = accuracy_score(y_test_split, y_pred)\n",
    "        accuracy_results[clf_name] = accuracy\n",
    "\n",
    "        # Plot confusion matrix in subplots\n",
    "        plot_and_save_confusion_matrix(le.inverse_transform(y_test_split), le.inverse_transform(y_pred), clf_name, axes[i // num_cols][i % num_cols])\n",
    "\n",
    "    # Hide empty subplots if there are fewer classifiers than columns\n",
    "    for i in range(num_classifiers, num_rows * num_cols):\n",
    "        axes[i // num_cols][i % num_cols].axis('off')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()  # Adjust bottom padding for the second row\n",
    "    plt.show()\n",
    "\n",
    "    res = pd.DataFrame(list(accuracy_results.items()), columns=['Classifier', 'Accuracy'])\n",
    "\n",
    "    # Create a bar plot using seaborn with annotations\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.barplot(x='Classifier', y='Accuracy', data=res, palette='viridis')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy of Classifiers')\n",
    "    plt.ylim(0, 1)  # Set the y-axis limit from 0 to 1 for accuracy values\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability if needed\n",
    "\n",
    "    # Add annotations for accuracy values on top of each bar\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.3f}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='bottom', fontsize=8, color='black', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnotherMethodNutriScore(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def AnotherMethodNutriScore(data):\n",
    "#     # Select columns of interest\n",
    "#     columns_of_interest = ['energy-kj_100g', 'sugars_100g', 'salt_100g', 'saturated-fat_100g',\n",
    "#                            'proteins_100g', 'fiber_100g', 'fruits-vegetables-nuts-estimate-from-ingredients_100g', 'sodium_100g',\n",
    "#                            'nutrition_grade_fr']  # Include the target column\n",
    "\n",
    "#     # Filter the dataset to columns of interest\n",
    "#     filtered_data = data[columns_of_interest]\n",
    "\n",
    "#     # Handle missing values if any\n",
    "#     filtered_data.dropna(inplace=True)\n",
    "\n",
    "#     # Separate features and target variable\n",
    "#     X = filtered_data.drop('nutrition_grade_fr', axis=1)\n",
    "#     y = filtered_data['nutrition_grade_fr']\n",
    "\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize and train the Decision Tree Classifier\n",
    "#     clf = DecisionTreeClassifier(random_state=42)\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     # Predict Nutri-scores\n",
    "#     predicted_scores = clf.predict(X_test)\n",
    "\n",
    "#     # Model evaluation\n",
    "#     accuracy = accuracy_score(y_test, predicted_scores)\n",
    "#     print(f\"Accuracy of the model: {accuracy}\")\n",
    "\n",
    "#     # Get the IDs of the test set\n",
    "#     test_ids = X_test.index.tolist()\n",
    "\n",
    "#     # Create a DataFrame to store IDs, original and predicted Nutri-scores\n",
    "#     results = pd.DataFrame({\n",
    "#         '_id': test_ids,\n",
    "#         'Original_NutriScore': y_test.values,\n",
    "#         'Predicted_NutriScore': predicted_scores\n",
    "#     })\n",
    "\n",
    "#     return results, X_test, y_test, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_nutri_scores, X_test, y_test, clf = AnotherMethodNutriScore(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a confusion matrix using crosstab\n",
    "# confusion_matrix = pd.crosstab(predicted_nutri_scores['Original_NutriScore'], predicted_nutri_scores['Predicted_NutriScore'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix)\n",
    "# # Plotting the confusion matrix as a heatmap using Seaborn\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
